{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "手書きの画像を入力し、漢数字の一～十を識別します。\n",
    "深層学習プログラミングの学習を目的として作成しました。\n",
    "\n",
    "ラベルデータの用意からモデルの作成、学習、推論までの一通りの流れを確認できます。\n",
    "\n",
    "### リポジトリ\n",
    "\n",
    "GitHubの以下のリポジトリして公開しています。\n",
    "\n",
    "\n",
    "\n",
    "### ディレクトリ構成\n",
    "\n",
    "* label・・・教師データです。ディレクトリ名をラベル名として認識します。ラベル名に対応するディレクトリ配下に対応する画像データを配置しています。\n",
    "* target・・・推論フェーズで使用するテストデータです。targetディレクトリに配下の画像を読み取り、それぞれどの分類になるかを推論します。\n",
    "\n",
    "### 説明の流れ\n",
    "\n",
    "以降はソースコード、その直後に解説という構成でプログラムを説明しています。\n",
    "全体の構成は以下のとおりです。\n",
    "\n",
    "* ライブラリのインポート\n",
    "* 関数定義\n",
    "    * 画像を読み込んでベクトルに変換するための関数\n",
    "    * ディレクトリを指定してラベルデータを読み込むための関数\n",
    "    * モデルの作成と学習をするための関数\n",
    "* 学習フェーズ\n",
    "* テストデータによる評価\n",
    "* 推論フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート\n",
    "\n",
    "以下のライブラリをインポートしています。\n",
    "\n",
    "* PIL・・・画像処理ライブラリ。画像のリサイズや、グレイスケールへの変換で使用。\n",
    "* numpy・・・言わずと知れた行列計算用ライブラリ。\n",
    "* os・・・ファイルやディレクトリのパスの操作で使用。\n",
    "* glob・・・ファイルやディレクトリを検索するためのユーティリティ。ワイルドカードで一括検索などが可能。便利。\n",
    "* keras・・・TensorFlowなどのディープラーニング用エンジンを簡単に利用するためのフレームワーク。凄い。\n",
    "* sklearn・・・scikit learn。機械学習で使用する色々な機能を提供。ここでは、交差検証のために開発データとテストデータの分離、および評価結果を表示するための関数を利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as Np\n",
    "import os as Os\n",
    "import glob as Glob\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist as Mnist\n",
    "from keras import utils as Utils\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を読み込んでベクトルに変換するための関数\n",
    "\n",
    "引数に指定された画像ファイルのパスを読み込み、以下の処理を行います。\n",
    "\n",
    "* リサイズ(グローバル変数のimage_width、 image_heightで指定したサイズにリサイズ)\n",
    "* グレイスケールに変換\n",
    "* 2値化(白: 0、黒: 1)\n",
    "\n",
    "最後にベクトル(1次元配列)に変形したndarrayを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_vector(image_filepath):\n",
    "    global image_width, image_height\n",
    "    \n",
    "    image = Image.open(image_filepath, 'r')\n",
    "    resized_image = image.resize((image_width, image_height))\n",
    "    gray_image = resized_image.convert('L')\n",
    "    onehot_image = gray_image.point(lambda x: 1 if x < 150 else 0)\n",
    "\n",
    "    array = Np.reshape(onehot_image, (image_width * image_height))\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ディレクトリを指定してラベルデータを読み込むための関数\n",
    "\n",
    "ラベルデータを保存したディレクトリのパスを受け取り、以下の3つの値を返します。\n",
    "\n",
    "* vectors・・・画像をベクトル化したデータ。\n",
    "* labels・・・ラベルの配列。vectorsの配列要素の順序に対応したラベルが保存されている。\n",
    "* printable_labels・・・ラベルデータが保存されているディレクトリ名を保存したもの。推論した後に返されるのは、ラベルの配列の要素番号であるため、それを人がわかる形に変換するために使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labeldata(label_path):\n",
    "    label_dirs = Glob.glob(Os.path.join(label_path, '*'))\n",
    "    labels = []\n",
    "    vectors = []\n",
    "    printable_labels = {}\n",
    "    class_count= len(label_dirs)\n",
    "\n",
    "    for i, label_dir in enumerate(label_dirs):\n",
    "        printable_labels[i] = Os.path.basename(label_dir)\n",
    "        image_dirs = Glob.glob(Os.path.join(label_dir, '*.jpg'))\n",
    "        for t, image_file in enumerate(image_dirs):\n",
    "            vector = convert_image_to_vector(image_file)\n",
    "            labels.append(i)\n",
    "            vectors.append(vector)\n",
    "    \n",
    "    reshaped_labels = Utils.np_utils.to_categorical(labels, num_classes = class_count)\n",
    "    reshaped_vectors = Np.asarray(vectors)\n",
    "\n",
    "    return {\n",
    "        'vectors': reshaped_vectors,\n",
    "        'labels': reshaped_labels,\n",
    "        'printable_labels': printable_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成と学習をするための関数\n",
    "\n",
    "class_countとして受け取った分類をするためのモデルを作成し、ラベルデータから学習を行います。\n",
    "\n",
    "作成するモデルは、全結合とDropoutを交互に重ねた3層構造です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(class_count, train_labels, train_vectors):\n",
    "    global image_width\n",
    "    global image_height\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 512, activation = 'relu', input_dim = (image_width * image_height)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(units = 512, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = class_count, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer = 'rmsprop',\n",
    "                 metrics = ['acc'])\n",
    "    tensor_board = TensorBoard(log_dir = 'tflog')\n",
    "    model.fit(train_vectors, train_labels, verbose = 1, epochs = 30, callbacks = [tensor_board])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習フェーズ\n",
    "\n",
    "学習に渡す前に開発データとテストデータ8:2の比率で別け、それぞれをモデルに渡して学習を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hideki/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/30\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.4653 - acc: 0.5161\n",
      "Epoch 2/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.1174 - acc: 0.9677\n",
      "Epoch 3/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 4/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 5/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 6/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 7/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 8/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0135 - acc: 0.9935\n",
      "Epoch 9/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 4.4356e-04 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 6.0559e-04 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 9.4518e-04 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 4.2408e-04 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 8.3154e-05 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 5.9973e-04 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 5.9789e-04 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 5.7693e-05 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 9.5239e-05 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 2.5447e-04 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 2.2102e-04 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 4.2461e-05 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.2166e-04 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.0128 - acc: 0.9935\n",
      "Epoch 27/30\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 8.1067e-06 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 3.4963e-05 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 9.1907e-07 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 3.0052e-06 - acc: 1.0000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               4454912   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,722,698\n",
      "Trainable params: 4,722,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "image_width = 100\n",
    "image_height= int(image_width * 0.87)\n",
    "\n",
    "label_data = load_labeldata('label')\n",
    "tmp_data = train_test_split(label_data['vectors'], label_data['labels'], train_size = 0.8, test_size = 0.2)\n",
    "train_vectors, test_vectors, train_labels, test_labels = map(lambda vec: Np.asarray(vec), tmp_data)\n",
    "class_count = len(label_data['printable_labels'])\n",
    " \n",
    "model = create_model(class_count, train_labels, train_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータによる評価\n",
    "\n",
    "テストデータに対して推論を行い、精度、検出率、F1値を算出しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          十       1.00      1.00      1.00         4\n",
      "          二       1.00      1.00      1.00         2\n",
      "          三       1.00      1.00      1.00         6\n",
      "          一       1.00      1.00      1.00         4\n",
      "          四       1.00      1.00      1.00         5\n",
      "          八       1.00      1.00      1.00         5\n",
      "          五       1.00      1.00      1.00         3\n",
      "          九       1.00      1.00      1.00         1\n",
      "          六       1.00      1.00      1.00         5\n",
      "          七       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#score = model.evaluate(test_vectors, test_labels)\n",
    "#print(score)\n",
    "#print('Loss = ', score[0])\n",
    "#print('Accuracy = ', score[1])\n",
    "\n",
    "pred_labels = model.predict_classes(test_vectors)\n",
    "numeric_labels = [i for i in test_labels.argmax(axis = 1)]\n",
    "print(classification_report(numeric_labels, pred_labels, target_names = label_data['printable_labels'].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論フェーズ\n",
    "\n",
    "`target`ディレクトリにある画像をファイルに対して推論を行い、結果を出力しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target/IMG_0206.jpg</th>\n",
       "      <td>五</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0261.jpg</th>\n",
       "      <td>六</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0262.jpg</th>\n",
       "      <td>七</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0263.jpg</th>\n",
       "      <td>八</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0264.jpg</th>\n",
       "      <td>九</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0265.jpg</th>\n",
       "      <td>十</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/paint_4.jpg</th>\n",
       "      <td>四</td>\n",
       "      <td>0.196821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/paint_5.jpg</th>\n",
       "      <td>三</td>\n",
       "      <td>0.284940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0195.jpg</th>\n",
       "      <td>四</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0194.jpg</th>\n",
       "      <td>三</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0193.jpg</th>\n",
       "      <td>二</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target/IMG_0192.jpg</th>\n",
       "      <td>一</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label  probability\n",
       "target/IMG_0206.jpg     五     1.000000\n",
       "target/IMG_0261.jpg     六     1.000000\n",
       "target/IMG_0262.jpg     七     0.999998\n",
       "target/IMG_0263.jpg     八     1.000000\n",
       "target/IMG_0264.jpg     九     1.000000\n",
       "target/IMG_0265.jpg     十     1.000000\n",
       "target/paint_4.jpg      四     0.196821\n",
       "target/paint_5.jpg      三     0.284940\n",
       "target/IMG_0195.jpg     四     1.000000\n",
       "target/IMG_0194.jpg     三     1.000000\n",
       "target/IMG_0193.jpg     二     1.000000\n",
       "target/IMG_0192.jpg     一     1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(result, labels):\n",
    "    return labels[result.argmax()]\n",
    "\n",
    "test_dirs = Glob.glob(Os.path.join('target', '*.jpg'))\n",
    "\n",
    "report = []\n",
    "files = []\n",
    "for i, image in enumerate(test_dirs):\n",
    "    vector = convert_image_to_vector(image)\n",
    "    result = model.predict(Np.array([vector]))\n",
    "    label = get_label(result[0], label_data['printable_labels'])\n",
    "    files.append(image)\n",
    "    report.append({\n",
    "        'label': label,\n",
    "        'probability': result.max()\n",
    "    })\n",
    "\n",
    "r = pd.DataFrame(report, index = files)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
